{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://docus.ai/glossary/biomarkers'\n",
    "response = requests.get(url)\n",
    "content = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "cards = soup.find_all('div', class_='ant-col ant-col-xs-24 css-1drr2mu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for card in cards:\n",
    "    link = card.find('a')\n",
    "    if(link):\n",
    "        if not link.get('href').startswith('/tags'):\n",
    "            links.append(link.get('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "while True:\n",
    "    url = f'https://docus.ai/glossary/biomarkers?page={page}'\n",
    "    response = requests.get(url)\n",
    "    content = response.text\n",
    "    if 'No results found' in content:\n",
    "        break\n",
    "    \n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    cards = soup.find_all('div', class_='ant-col ant-col-xs-24 css-1drr2mu')\n",
    "    for card in cards:\n",
    "        link = card.find('a')\n",
    "        if(link):\n",
    "            if not link.get('href').startswith('/tags'):\n",
    "                links.append(link.get('href'))\n",
    "    page += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomarkers_glossary = {}\n",
    "\n",
    "for url in links: \n",
    "    response = requests.get(f\"https://docus.ai/{url}\")\n",
    "    content = response.text\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    page_content = soup.find('section', class_='sc-5d4eaeca-0 htRsFi sc-fdf5dc80-0 gsFBbo')\n",
    "    content_div = page_content.find_all('div')\n",
    "\n",
    "    text = ''\n",
    "    for i in page_content.find_all('div', recursive=False)[2:]:\n",
    "        text += i.get_text() + \"\\n\"\n",
    "\n",
    "    biomarkers_glossary[soup.find(\"h1\").text] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "biomarkers_glossary_df = pd.DataFrame(biomarkers_glossary.items(), columns=['Topic', 'Content'])\n",
    "biomarkers_glossary_df.to_csv('biomarkers_glossary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make each entry into a txt file\n",
    "for key, value in biomarkers_glossary.items():\n",
    "    with open(f'biomarkers_glossary/{key}.txt', 'w') as file:\n",
    "        file.write(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleveland Clinic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://my.clevelandclinic.org/health/diagnostics/4053-complete-blood-count\"\n",
    "response = requests.get(url)\n",
    "content = response.text\n",
    "\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "page_content = soup.find('div', {'data-identity': 'main-article-content'})\n",
    "\n",
    "cleveland_cbc_text = soup.find('h1').text + \"\\n\"\n",
    "for i in page_content.find_all('div', recursive=False)[1:-1]:\n",
    "    cleveland_cbc_text += i.get_text() + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for link in page_content.find_all('a'):\n",
    "    if link.get('href').startswith('https://my.clevelandclinic.org/'):\n",
    "        links.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for link in links: \n",
    "    try: \n",
    "        response = requests.get(link)\n",
    "        content = response.text\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "        page_content = soup.find('div', {'data-identity': 'main-article-content'})\n",
    "        cleveland_cbc_text += soup.find('h1').text + \"\\n\"\n",
    "        print(soup.find('h1').text)\n",
    "\n",
    "        for i in page_content.find_all('div', recursive=False)[1:-1]:\n",
    "            cleveland_cbc_text += i.get_text() + \"\\n\"\n",
    "\n",
    "        for link in page_content.find_all('a'):\n",
    "            if link.get('href').startswith('https://my.clevelandclinic.org/'):\n",
    "                if(link.get('href') not in links):\n",
    "                    links.append(link.get('href'))\n",
    "    except: \n",
    "        print(link)\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to a text file\n",
    "with open('cleveland_clinic.txt', 'w') as file:\n",
    "    file.write(cleveland_cbc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(links).to_csv(\"cleveland_clinic_links.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
